{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlQJsJ3UXbDN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kI0thePgDi_G"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import mixed_precision\n",
        "import gc\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0EytR4iSDkBk"
      },
      "outputs": [],
      "source": [
        "# Set memory growth to avoid pre-allocating all GPU memory\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "    for device in physical_devices:\n",
        "        tf.config.experimental.set_memory_growth(device, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pxGn4x0DlWA"
      },
      "outputs": [],
      "source": [
        "# Use mixed precision to reduce memory usage\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Load dataset with even smaller percentage (10% instead of 20%)\n",
        "(train_ds, test_ds), ds_info = tfds.load(\n",
        "    \"food101\",\n",
        "    split=[\"train[:30%]\", \"validation[:20%]\"],\n",
        "    as_supervised=True,\n",
        "    with_info=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vTLANJS2DpDI"
      },
      "outputs": [],
      "source": [
        "# Further reduce the image size\n",
        "IMG_SIZE = (128, 128)  # smaller than original 150x150\n",
        "\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, IMG_SIZE)\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3T7_DYADqnZ"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "SHUFFLE_BUFFER = 200  # Smaller shuffle buffer\n",
        "\n",
        "# Avoid caching to disk to prevent memory issues\n",
        "train_ds = (train_ds\n",
        "            .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "            .batch(BATCH_SIZE)\n",
        "            .shuffle(SHUFFLE_BUFFER)\n",
        "            .prefetch(tf.data.AUTOTUNE))\n",
        "\n",
        "test_ds = (test_ds\n",
        "           .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "           .batch(BATCH_SIZE)\n",
        "           .prefetch(tf.data.AUTOTUNE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iCtCD8LfDtbS"
      },
      "outputs": [],
      "source": [
        "# Use a more efficient backbone model\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    alpha=1.0  # Using a smaller width multiplier for fewer parameters\n",
        ")\n",
        "base_model.trainable = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BVoFNUeGDuz9"
      },
      "outputs": [],
      "source": [
        "# Create a more efficient model architecture\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),  # Smaller dense layer\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(101, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7A8LDxtwDwV9"
      },
      "outputs": [],
      "source": [
        "# Compile with mixed precision optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "optimizer = mixed_precision.LossScaleOptimizer(optimizer)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42-eJRtIDzcf",
        "outputId": "3042cab5-f54d-441c-f0e3-c8cd5e6a710e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r\u001b[1m  1/356\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2:11:00\u001b[0m 22s/step - accuracy: 0.3750 - loss: 2.6797"
          ]
        }
      ],
      "source": [
        "# Create a custom callback to clear memory after each epoch\n",
        "class MemoryCleanupCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()\n",
        "        tf.keras.backend.clear_session()\n",
        "        print(f\"\\nMemory cleaned after epoch {epoch+1}\\n\")\n",
        "\n",
        "# Train with memory cleanup\n",
        "EPOCHS = 30\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=test_ds,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[\n",
        "        MemoryCleanupCallback(),\n",
        "        # Save only the best model to avoid storing multiple versions\n",
        "        tf.keras.callbacks.ModelCheckpoint(\n",
        "            'best_model.h5',\n",
        "            save_best_only=True,\n",
        "            monitor='val_accuracy'\n",
        "        ),\n",
        "        # Early stopping to prevent unnecessary epochs\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_accuracy',\n",
        "            patience=3\n",
        "        )\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCLzUb6CD11h"
      },
      "outputs": [],
      "source": [
        "# Clean up before evaluation\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZdtJV8-D4NK"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_ds)\n",
        "print(f\"Test accuracy: {test_acc:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCWqdVkCsGOq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6i7HXB4sGOr"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import mixed_precision\n",
        "import gc\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6F7_tCPhsGOs"
      },
      "outputs": [],
      "source": [
        "# Set memory growth to avoid pre-allocating all GPU memory\n",
        "physical_devices = tf.config.list_physical_devices('GPU')\n",
        "if physical_devices:\n",
        "    for device in physical_devices:\n",
        "        tf.config.experimental.set_memory_growth(device, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o6QzXJ4ZsGOs"
      },
      "outputs": [],
      "source": [
        "# Use mixed precision to reduce memory usage\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# Load dataset with even smaller percentage (10% instead of 20%)\n",
        "(train_ds, test_ds), ds_info = tfds.load(\n",
        "    \"food101\",\n",
        "    split=[\"train[:30%]\", \"validation[:20%]\"],\n",
        "    as_supervised=True,\n",
        "    with_info=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GmIRn0PsGOu"
      },
      "outputs": [],
      "source": [
        "# Further reduce the image size\n",
        "IMG_SIZE = (128, 128)  # smaller than original 150x150\n",
        "\n",
        "def preprocess(image, label):\n",
        "    image = tf.image.resize(image, IMG_SIZE)\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxkLTuq7sGOv"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "SHUFFLE_BUFFER = 200  # Smaller shuffle buffer\n",
        "\n",
        "# Avoid caching to disk to prevent memory issues\n",
        "train_ds = (train_ds\n",
        "            .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "            .batch(BATCH_SIZE)\n",
        "            .shuffle(SHUFFLE_BUFFER)\n",
        "            .prefetch(tf.data.AUTOTUNE))\n",
        "\n",
        "test_ds = (test_ds\n",
        "           .map(preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "           .batch(BATCH_SIZE)\n",
        "           .prefetch(tf.data.AUTOTUNE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9oF0svvtsGOv"
      },
      "outputs": [],
      "source": [
        "# Use a more efficient backbone model\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    alpha=0.75  # Using a smaller width multiplier for fewer parameters\n",
        ")\n",
        "base_model.trainable = False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pmYfJJ1jsGOw"
      },
      "outputs": [],
      "source": [
        "# Create a more efficient model architecture\n",
        "model = tf.keras.Sequential([\n",
        "    base_model,\n",
        "    tf.keras.layers.GlobalAveragePooling2D(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),  # Smaller dense layer\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(101, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpO7KOHKsGOw"
      },
      "outputs": [],
      "source": [
        "# Compile with mixed precision optimizer\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "optimizer = mixed_precision.LossScaleOptimizer(optimizer)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=optimizer,\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RgnLuOQsGOw"
      },
      "outputs": [],
      "source": [
        "# Create a custom callback to clear memory after each epoch\n",
        "class MemoryCleanupCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()\n",
        "        tf.keras.backend.clear_session()\n",
        "        print(f\"\\nMemory cleaned after epoch {epoch+1}\\n\")\n",
        "\n",
        "# Train with memory cleanup\n",
        "EPOCHS = 30\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    validation_data=test_ds,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=[\n",
        "        MemoryCleanupCallback(),\n",
        "        # Save only the best model to avoid storing multiple versions\n",
        "        tf.keras.callbacks.ModelCheckpoint(\n",
        "            'best_model.h5',\n",
        "            save_best_only=True,\n",
        "            monitor='val_accuracy'\n",
        "        ),\n",
        "        # Early stopping to prevent unnecessary epochs\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_accuracy',\n",
        "            patience=3\n",
        "        )\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VggVMNm3sGOx"
      },
      "outputs": [],
      "source": [
        "# Clean up before evaluation\n",
        "gc.collect()\n",
        "tf.keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPRh1gNZsGOx"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_ds)\n",
        "print(f\"Test accuracy: {test_acc:.2%}\")"
      ]
    }
  ]
}